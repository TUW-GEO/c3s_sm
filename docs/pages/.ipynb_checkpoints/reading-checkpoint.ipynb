{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reading C3S SM data in python\n",
    "\n",
    "## With xarray\n",
    "\n",
    "The easiest way to load C3S SM image data as downloaded from CDS into memory\n",
    "is by using [xarray](https://docs.xarray.dev/en/stable/).\n",
    "\n",
    "When xarray is installed, it can be used to load one or multiple C3S SM\n",
    "images into memory and merge them into a data cube along the time dimension.\n",
    "\n",
    "### Loading a single C3S SM netcdf image\n",
    "In the first example we simply load one image as an xarray Dataset:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "377c94b335c2d012"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# to install xarray see https://docs.xarray.dev/en/stable/\n",
    "import xarray as xr\n",
    "img = xr.open_dataset(\"./../../tests/c3s_sm-test-data/img/TCDR/060_dailyImages/combined/2014/C3S-SOILMOISTURE-L3S-SSMV-COMBINED-DAILY-20140101000000-TCDR-v201801.0.0.nc\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-29T13:47:23.424302Z",
     "start_time": "2024-08-29T13:47:23.411909Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "From there on we can use xarray functionality extract numpy array, plot data, convert them into pandas DataFrames etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52ee63ccc34306b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading and stacking multiple C3S SM images\n",
    "\n",
    "To load multiple images at once, we can use `xarray.open_mfdataset`. For this\n",
    "we have to make sure that the [`dask` library](https://www.dask.org/) is installed (e.g. via \n",
    "``conda install dask``). In the example below we just load 2 images from the\n",
    "test data.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c25cd32872ef82c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized chunk manager dask - must be one of: []",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#  - conda install dask - https://www.dask.org/\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mxarray\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mxr\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mxr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_mfdataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./../../tests/c3s_sm-test-data/img/TCDR/060_dailyImages/combined/**/*.nc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m ds\n",
      "File \u001B[0;32m~/miniforge3/envs/c3s_sm/lib/python3.12/site-packages/xarray/backends/api.py:1077\u001B[0m, in \u001B[0;36mopen_mfdataset\u001B[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001B[0m\n\u001B[1;32m   1074\u001B[0m     open_ \u001B[38;5;241m=\u001B[39m open_dataset\n\u001B[1;32m   1075\u001B[0m     getattr_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m\n\u001B[0;32m-> 1077\u001B[0m datasets \u001B[38;5;241m=\u001B[39m [\u001B[43mopen_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopen_kwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m paths]\n\u001B[1;32m   1078\u001B[0m closers \u001B[38;5;241m=\u001B[39m [getattr_(ds, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_close\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m ds \u001B[38;5;129;01min\u001B[39;00m datasets]\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preprocess \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/c3s_sm/lib/python3.12/site-packages/xarray/backends/api.py:594\u001B[0m, in \u001B[0;36mopen_dataset\u001B[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m    587\u001B[0m overwrite_encoded_chunks \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverwrite_encoded_chunks\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    588\u001B[0m backend_ds \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mopen_dataset(\n\u001B[1;32m    589\u001B[0m     filename_or_obj,\n\u001B[1;32m    590\u001B[0m     drop_variables\u001B[38;5;241m=\u001B[39mdrop_variables,\n\u001B[1;32m    591\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdecoders,\n\u001B[1;32m    592\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    593\u001B[0m )\n\u001B[0;32m--> 594\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43m_dataset_from_backend_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverwrite_encoded_chunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m    \u001B[49m\u001B[43minline_array\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked_array_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrom_array_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdrop_variables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_variables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdecoders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ds\n",
      "File \u001B[0;32m~/miniforge3/envs/c3s_sm/lib/python3.12/site-packages/xarray/backends/api.py:370\u001B[0m, in \u001B[0;36m_dataset_from_backend_dataset\u001B[0;34m(backend_ds, filename_or_obj, engine, chunks, cache, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001B[0m\n\u001B[1;32m    368\u001B[0m     ds \u001B[38;5;241m=\u001B[39m backend_ds\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 370\u001B[0m     ds \u001B[38;5;241m=\u001B[39m \u001B[43m_chunk_ds\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbackend_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverwrite_encoded_chunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[43m        \u001B[49m\u001B[43minline_array\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked_array_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_array_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    382\u001B[0m ds\u001B[38;5;241m.\u001B[39mset_close(backend_ds\u001B[38;5;241m.\u001B[39m_close)\n\u001B[1;32m    384\u001B[0m \u001B[38;5;66;03m# Ensure source filename always stored in dataset object\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/c3s_sm/lib/python3.12/site-packages/xarray/backends/api.py:318\u001B[0m, in \u001B[0;36m_chunk_ds\u001B[0;34m(backend_ds, filename_or_obj, engine, chunks, overwrite_encoded_chunks, inline_array, chunked_array_type, from_array_kwargs, **extra_tokens)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_chunk_ds\u001B[39m(\n\u001B[1;32m    308\u001B[0m     backend_ds,\n\u001B[1;32m    309\u001B[0m     filename_or_obj,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mextra_tokens,\n\u001B[1;32m    317\u001B[0m ):\n\u001B[0;32m--> 318\u001B[0m     chunkmanager \u001B[38;5;241m=\u001B[39m \u001B[43mguess_chunkmanager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunked_array_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;66;03m# TODO refactor to move this dask-specific logic inside the DaskManager class\u001B[39;00m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunkmanager, DaskManager):\n",
      "File \u001B[0;32m~/miniforge3/envs/c3s_sm/lib/python3.12/site-packages/xarray/namedarray/parallelcompat.py:117\u001B[0m, in \u001B[0;36mguess_chunkmanager\u001B[0;34m(manager)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(manager, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m chunkmanagers:\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    118\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munrecognized chunk manager \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmanager\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - must be one of: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(chunkmanagers)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    119\u001B[0m         )\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m chunkmanagers[manager]\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(manager, ChunkManagerEntrypoint):\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;66;03m# already a valid ChunkManager so just pass through\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: unrecognized chunk manager dask - must be one of: []"
     ]
    }
   ],
   "source": [
    "import dask   # make sure dask is installed\n",
    "#  - conda install dask - https://www.dask.org/\n",
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_mfdataset(\"./../../tests/c3s_sm-test-data/img/TCDR/060_dailyImages/combined/**/*.nc\")\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T13:47:23.487983Z",
     "start_time": "2024-08-29T13:47:23.432086Z"
    }
   },
   "id": "ec7001504aaacfc7",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afterwards the image data will be loaded as dask arrays, and we can select\n",
    "time stamps to extract from the stack."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2fd72ae8377ab6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract the first time stamp and a spatial subset\n",
    "img = ds.isel(time=0).sel(lon=slice(-20, 40), lat=slice(60, 30))\n",
    "img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b0aa781d5913bc0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With c3s_sm.interface\n",
    "We provide our own image readers in this package. They are mainly used for the conversion\n",
    "to time series, but can also be used to load the data as numpy arrays. They are based on \n",
    "the netCDF4 python package (don't require xarray). There is one reader\n",
    "to read a single netcdf file, and one to find the image for a date in a file collection.\n",
    "\n",
    "For most users the above described use of xarray is probably preferred!\n",
    "\n",
    "### Image reader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f0a6530658cfee7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from c3s_sm.interface import C3SImg\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "img = C3SImg(\"./../../tests/c3s_sm-test-data/img/TCDR/060_dailyImages/combined/2014/C3S-SOILMOISTURE-L3S-SSMV-COMBINED-DAILY-20140101000000-TCDR-v201801.0.0.nc\").read(datetime(2014,1,1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "341e3469ea4e236",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will create an Image object which is basically just a container for numpy arrays, netcdf attributes and dimension variables (lat, lon, time)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "603ffc8037c94fa7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.data['sm'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee094cd218caaee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"Image coordinates\", img.lat, img.lon, img.timestamp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fd94ceb0bdcead9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-image reader\n",
    "\n",
    "The image to time series conversion requires a class that reads image data for a time stamp from a directory with multiple files. The class is used as follows:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b13fe620e54260"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from c3s_sm.interface import C3S_Nc_Img_Stack\n",
    "from datetime import datetime\n",
    "\n",
    "stack = C3S_Nc_Img_Stack(\"./../../tests/c3s_sm-test-data/img/TCDR/060_dailyImages/combined/\", fillval=np.nan)\n",
    "ts = datetime(2014, 1, 1)\n",
    "image = stack.read(ts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea60a4a0297b9619",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(image.data['sm'])\n",
    "plt.title(f\"SM at {str(ts.date())}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f62aaaad53276709",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
